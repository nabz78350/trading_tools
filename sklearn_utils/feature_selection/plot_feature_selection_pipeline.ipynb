{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Pipeline ANOVA SVM\n",
        "\n",
        "This example shows how a feature selection can be easily integrated within\n",
        "a machine learning pipeline.\n",
        "\n",
        "We also show that you can easily inspect part of the pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will start by generating a binary classification dataset. Subsequently, we\n",
        "will divide the dataset into two subsets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_features=20,\n",
        "    n_informative=3,\n",
        "    n_redundant=0,\n",
        "    n_classes=2,\n",
        "    n_clusters_per_class=2,\n",
        "    random_state=42,\n",
        ")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A common mistake done with feature selection is to search a subset of\n",
        "discriminative features on the full dataset, instead of only using the\n",
        "training set. The usage of scikit-learn :func:`~sklearn.pipeline.Pipeline`\n",
        "prevents to make such mistake.\n",
        "\n",
        "Here, we will demonstrate how to build a pipeline where the first step will\n",
        "be the feature selection.\n",
        "\n",
        "When calling `fit` on the training data, a subset of feature will be selected\n",
        "and the index of these selected features will be stored. The feature selector\n",
        "will subsequently reduce the number of features, and pass this subset to the\n",
        "classifier which will be trained.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explanation of SelectKBest\n",
        "\n",
        "`SelectKBest` is a feature selection method in scikit-learn that selects the top `k` features based on a specified scoring function. It helps in reducing the dimensionality of the feature space, improving model performance and interpretability.\n",
        "\n",
        "## How SelectKBest Works\n",
        "\n",
        "### Arguments:\n",
        "- `score_func`: The scoring function to evaluate the importance of features. Common options are:\n",
        "  - `f_classif`: ANOVA F-value between label/feature for classification tasks.\n",
        "  - `chi2`: Chi-squared statistic between label/feature for classification tasks.\n",
        "  - `mutual_info_classif`: Mutual information for a discrete target.\n",
        "  - `f_regression`: F-value between label/feature for regression tasks.\n",
        "  - `mutual_info_regression`: Mutual information for a continuous target.\n",
        "- `k`: Number of top features to select. Can be an integer or `\"all\"` to select all features.\n",
        "\n",
        "### Math Behind SelectKBest:\n",
        "- **f_classif (ANOVA F-value)**:\n",
        "  - Computes the ANOVA F-value for each feature.\n",
        "  - The F-value measures the ratio of variance between the groups to the variance within the groups.\n",
        "  - A higher F-value indicates that the feature is more likely to be significant.\n",
        "\n",
        "The formula for F-value in ANOVA:\n",
        "$\\ F = \\frac{MSR}{MSE} $\n",
        "where:\n",
        "- $\\ MSR $ is the mean square regression (variance between the groups).\n",
        "- $\\ MSE $ is the mean square error (variance within the groups).\n",
        "\n",
        "### Steps in Feature Selection with SelectKBest:\n",
        "1. **Compute the score**: For each feature, the scoring function (e.g., `f_classif`) computes a score that indicates the significance of the feature.\n",
        "2. **Rank the features**: Features are ranked based on their scores.\n",
        "3. **Select top k features**: The top `k` features with the highest scores are selected.\n",
        "\n",
        "### Example Usage:\n",
        "```python\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "# Select top 3 features using ANOVA F-value\n",
        "anova_filter = SelectKBest(f_classif, k=3)\n",
        "clf = LinearSVC()\n",
        "anova_svm = make_pipeline(anova_filter, clf)\n",
        "anova_svm.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;selectkbest&#x27;, SelectKBest(k=7)), (&#x27;linearsvc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;selectkbest&#x27;, SelectKBest(k=7)), (&#x27;linearsvc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=7)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('selectkbest', SelectKBest(k=7)), ('linearsvc', LinearSVC())])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "anova_filter = SelectKBest(f_classif, k=7)\n",
        "clf = LinearSVC()\n",
        "anova_svm = make_pipeline(anova_filter, clf)\n",
        "anova_svm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the training is complete, we can predict on new unseen samples. In this\n",
        "case, the feature selector will only select the most discriminative features\n",
        "based on the information stored during training. Then, the data will be\n",
        "passed to the classifier which will make the prediction.\n",
        "\n",
        "Here, we show the final metrics via a classification report.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.73      0.85        15\n",
            "           1       0.71      1.00      0.83        10\n",
            "\n",
            "    accuracy                           0.84        25\n",
            "   macro avg       0.86      0.87      0.84        25\n",
            "weighted avg       0.89      0.84      0.84        25\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = anova_svm.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Be aware that you can inspect a step in the pipeline. For instance, we might\n",
        "be interested about the parameters of the classifier. Since we selected\n",
        "three features, we expect to have three coefficients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.20854111, 0.9276843 , 0.1472149 , 0.28023679, 0.16733161,\n",
              "        0.22735165, 0.29925922]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "anova_svm[-1].coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, we do not know which features were selected from the original\n",
        "dataset. We could proceed by several manners. Here, we will invert the\n",
        "transformation of these coefficients to get information about the original\n",
        "space.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.20854111, 0.9276843 , 0.        , 0.        ,\n",
              "        0.1472149 , 0.        , 0.        , 0.        , 0.28023679,\n",
              "        0.        , 0.        , 0.16733161, 0.        , 0.        ,\n",
              "        0.22735165, 0.        , 0.        , 0.        , 0.29925922]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "anova_svm[:-1].inverse_transform(anova_svm[-1].coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the features with non-zero coefficients are the selected\n",
        "features by the first step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
