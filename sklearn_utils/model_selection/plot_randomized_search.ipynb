{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Comparing randomized search and grid search for hyperparameter estimation\n",
        "\n",
        "Compare randomized search and grid search for optimizing hyperparameters of a\n",
        "linear SVM with SGD training.\n",
        "All parameters that influence the learning are searched simultaneously\n",
        "(except for the number of estimators, which poses a time / quality tradeoff).\n",
        "\n",
        "The randomized search and the grid search explore exactly the same space of\n",
        "parameters. The result in parameter settings is quite similar, while the run\n",
        "time for randomized search is drastically lower.\n",
        "\n",
        "The performance is may slightly worse for the randomized search, and is likely\n",
        "due to a noise effect and would not carry over to a held-out test set.\n",
        "\n",
        "Note that in practice, one would not search over this many different parameters\n",
        "simultaneously using grid search, but pick only the ones deemed most important.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomizedSearchCV\n",
        "\n",
        "#### Overview\n",
        "\n",
        "`RandomizedSearchCV` is a hyperparameter optimization technique that samples a given number of parameter settings from a specified distribution or set of values, instead of exhaustively searching through all possible combinations as in `GridSearchCV`. This approach allows for a more efficient search, especially when the parameter space is large.\n",
        "\n",
        "#### How It Works\n",
        "\n",
        "1. **Define Parameter Distributions**:\n",
        "   - Instead of defining a grid of parameters, you define a distribution for each parameter. This can be a uniform distribution, a normal distribution, or a list of discrete values.\n",
        "\n",
        "2. **Random Sampling**:\n",
        "   - A predefined number of parameter combinations are sampled randomly from these distributions. Each sampled combination is treated as a candidate set of parameters.\n",
        "\n",
        "3. **Model Evaluation**:\n",
        "   - Each candidate model is trained and evaluated using cross-validation.\n",
        "\n",
        "4. **Selection**:\n",
        "   - The combination of parameters that results in the best performance on the cross-validation set is selected.\n",
        "\n",
        "#### Mathematical Formulation\n",
        "\n",
        "Let:\n",
        "- $P$ be the number of parameters.\n",
        "- $n_{\\text{iter}}$ be the number of iterations (random samples) to be evaluated.\n",
        "- $\\Theta$ represent the parameter space.\n",
        "\n",
        "The process can be described as follows:\n",
        "\n",
        "1. **Parameter Sampling**:\n",
        "   - For each iteration $i$ (where $i \\in \\{1, \\dots, n_{\\text{iter}}\\}$):\n",
        "     - Randomly sample a parameter combination $\\theta_i \\in \\Theta$.\n",
        "\n",
        "2. **Model Training and Evaluation**:\n",
        "   - For each sampled combination $\\theta_i$:\n",
        "     - Train the model using the parameters $\\theta_i$.\n",
        "     - Evaluate the model's performance using cross-validation and record the score.\n",
        "\n",
        "3. **Selection**:\n",
        "   - Select the parameter combination $\\theta^*$ that yields the best cross-validation score:\n",
        "     $$\n",
        "     \\theta^* = \\arg\\max_{\\theta_i \\in \\{\\theta_1, \\theta_2, \\ldots, \\theta_{n_{\\text{iter}}}\\}} \\text{Score}(\\theta_i)\n",
        "     $$\n",
        "\n",
        "#### Differences from Classic GridSearchCV\n",
        "\n",
        "- **Efficiency**:\n",
        "  - `GridSearchCV` evaluates all possible combinations of parameters in the specified grid, which can be computationally expensive.\n",
        "  - `RandomizedSearchCV` evaluates a fixed number of randomly sampled parameter combinations, which is more efficient for large parameter spaces.\n",
        "\n",
        "- **Exploration**:\n",
        "  - `GridSearchCV` can miss optimal hyperparameter values if they lie between the grid points.\n",
        "  - `RandomizedSearchCV` has a higher chance of finding better hyperparameters since it samples from the entire distribution.\n",
        "\n",
        "- **Flexibility**:\n",
        "  - `GridSearchCV` requires the specification of exact grid points for each parameter.\n",
        "  - `RandomizedSearchCV` allows specifying distributions for parameters, providing more flexibility in the search process.\n",
        "\n",
        "- **Computational Cost**:\n",
        "  - `GridSearchCV` can become infeasible when the number of parameter combinations is large.\n",
        "  - `RandomizedSearchCV` is computationally more efficient, as the number of evaluations is fixed and can be controlled.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "`RandomizedSearchCV` offers a more efficient and flexible approach to hyperparameter optimization compared to `GridSearchCV`, particularly in large parameter spaces. By sampling a fixed number of parameter combinations from specified distributions, it can explore the parameter space more effectively and often converges to good solutions faster than an exhaustive grid search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomizedSearchCV took 0.69 seconds for 15 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.987 (std: 0.018)\n",
            "Parameters: {'alpha': 0.04826877924427789, 'average': False, 'l1_ratio': 0.8003590258043273}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.987 (std: 0.011)\n",
            "Parameters: {'alpha': 0.13968474245415072, 'average': False, 'l1_ratio': 0.6120622732189022}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.981 (std: 0.015)\n",
            "Parameters: {'alpha': 0.036448785708378256, 'average': False, 'l1_ratio': 0.8587670698156694}\n",
            "\n",
            "GridSearchCV took 2.49 seconds for 60 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.991 (std: 0.012)\n",
            "Parameters: {'alpha': 0.01, 'average': False, 'l1_ratio': 0.0}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.989 (std: 0.007)\n",
            "Parameters: {'alpha': 1.0, 'average': False, 'l1_ratio': 0.0}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.989 (std: 0.007)\n",
            "Parameters: {'alpha': 0.1, 'average': False, 'l1_ratio': 0.0}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.989 (std: 0.011)\n",
            "Parameters: {'alpha': 0.1, 'average': False, 'l1_ratio': 0.6666666666666666}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# get some data\n",
        "X, y = load_digits(return_X_y=True, n_class=3)\n",
        "\n",
        "# build a classifier\n",
        "clf = SGDClassifier(loss=\"hinge\", penalty=\"elasticnet\", fit_intercept=True)\n",
        "\n",
        "\n",
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\n",
        "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                    results[\"mean_test_score\"][candidate],\n",
        "                    results[\"std_test_score\"][candidate],\n",
        "                )\n",
        "            )\n",
        "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": stats.uniform(0, 1),\n",
        "    \"alpha\": stats.loguniform(1e-2, 1e0),\n",
        "}\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 15\n",
        "random_search = RandomizedSearchCV(\n",
        "    clf, param_distributions=param_dist, n_iter=n_iter_search\n",
        ")\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X, y)\n",
        "print(\n",
        "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
        "    % ((time() - start), n_iter_search)\n",
        ")\n",
        "report(random_search.cv_results_)\n",
        "\n",
        "# use a full grid over all parameters\n",
        "param_grid = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": np.linspace(0, 1, num=10),\n",
        "    \"alpha\": np.power(10, np.arange(-2, 1, dtype=float)),\n",
        "}\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
        "start = time()\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\n",
        "    \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "    % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
        ")\n",
        "report(grid_search.cv_results_)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
